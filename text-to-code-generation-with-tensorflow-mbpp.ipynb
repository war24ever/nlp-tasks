{"cells":[{"cell_type":"code","execution_count":null,"id":"2a495960","metadata":{"execution":{"iopub.execute_input":"2022-04-21T14:41:08.802692Z","iopub.status.busy":"2022-04-21T14:41:08.802136Z","iopub.status.idle":"2022-04-21T14:41:34.124951Z","shell.execute_reply":"2022-04-21T14:41:34.124136Z","shell.execute_reply.started":"2022-04-21T12:12:58.731052Z"},"papermill":{"duration":25.348195,"end_time":"2022-04-21T14:41:34.125085","exception":false,"start_time":"2022-04-21T14:41:08.776890","status":"completed"},"tags":[],"id":"2a495960","outputId":"7d75ae10-1df5-4e81-e387-4117608b6574"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n","TF version 2.6.2\n","Num GPUs Available:  1\n"]}],"source":["import os\n","import time\n","import math\n","import random\n","import datetime\n","from pathlib import Path\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # reduce the amount of console output from TF\n","import tensorflow as tf\n","\n","from transformers import *\n","!pip install -q datasets # install HF datasets library\n","from datasets import load_dataset\n","\n","logging.set_verbosity_warning()\n","logging.set_verbosity_error()\n","\n","import logging\n","\n","print('TF version',tf.__version__)\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) # check GPU available"]},{"cell_type":"code","execution_count":null,"id":"bab0a377","metadata":{"execution":{"iopub.execute_input":"2022-04-21T14:41:34.216338Z","iopub.status.busy":"2022-04-21T14:41:34.215392Z","iopub.status.idle":"2022-04-21T14:41:34.218572Z","shell.execute_reply":"2022-04-21T14:41:34.218991Z","shell.execute_reply.started":"2022-04-21T12:13:24.841197Z"},"papermill":{"duration":0.03458,"end_time":"2022-04-21T14:41:34.219150","exception":false,"start_time":"2022-04-21T14:41:34.184570","status":"completed"},"tags":[],"id":"bab0a377","outputId":"1a787548-51e6-4aaa-d7c4-9cd72a1d4786"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Tensorflow: setting up strategy\n"," XLA Enabled\n"," One Device Strategy [GPU] Enabled\n"]}],"source":["def setup_strategy(xla, fp16, no_cuda):\n","    print(\" Tensorflow: setting up strategy\")\n","\n","    # setup xla\n","    if xla:\n","        print(\" XLA Enabled\")\n","        tf.config.optimizer.set_jit(True)\n","\n","    # setup mixed precision training\n","    if fp16:\n","        # Set to float16 at first\n","        print(\" Mixed Precision Training Enabled\")\n","        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n","        tf.keras.mixed_precision.experimental.set_policy(policy)\n","\n","    # setup distribution strategy\n","    gpus = tf.config.list_physical_devices(\"GPU\")\n","    if no_cuda:\n","        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n","    else:\n","        if len(gpus) == 0:\n","            print(\" One Device Strategy [CPU] Enabled\")\n","            strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n","        elif len(gpus) == 1:\n","            print(\" One Device Strategy [GPU] Enabled\")\n","            strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n","        elif len(gpus) > 1:\n","            print(\" Mirrored Strategy Enabled\")\n","            # If only want to use a specific subset of GPUs use CUDA_VISIBLE_DEVICES=0`\n","            strategy = tf.distribute.MirroredStrategy()\n","        else:\n","            strategy = tf.distribute.get_strategy()\n","\n","    return strategy\n","\n","def n_replicas(strategy):\n","    # return number of devices\n","    return strategy.num_replicas_in_sync\n","\n","# note:\n","# huggingface TF-T5 implementation has issues when mixed precision is enabled\n","# we will disable FP16 for this but can be used for training any other model\n","strategy = setup_strategy(xla=True, fp16=False, no_cuda=False)"]},{"cell_type":"code","execution_count":null,"id":"70606042","metadata":{"execution":{"iopub.execute_input":"2022-04-21T14:41:34.316411Z","iopub.status.busy":"2022-04-21T14:41:34.315493Z","iopub.status.idle":"2022-04-21T14:41:34.318389Z","shell.execute_reply":"2022-04-21T14:41:34.317799Z","shell.execute_reply.started":"2022-04-21T12:13:24.856404Z"},"papermill":{"duration":0.040268,"end_time":"2022-04-21T14:41:34.318549","exception":false,"start_time":"2022-04-21T14:41:34.278281","status":"completed"},"tags":[],"id":"70606042"},"outputs":[],"source":["def download_dataset(cache_dir):\n","    # download data using a keras utility\n","    _url = \"https://raw.githubusercontent.com/google-research/google-research/master/mbpp/mbpp.jsonl\" # download mbpp dataset\n","    dataset_path = tf.keras.utils.get_file(\"mbpp.jsonl\", origin=_url, cache_dir=cache_dir, cache_subdir=cache_dir)\n","    return dataset_path\n","\n","def convert_examples_to_features(examples, tokenizer, args):\n","    # encode text-code pairs\n","    texts = examples['text']\n","    codes = examples['code']\n","    # tests = [\" \".join(test) for test in examples['test_list']] # convert list of test cases to single string\n","\n","    # encode texts by prepending the task for input sequence\n","    inputs = [args.prefix + text for text in texts]\n","    model_inputs = tokenizer(inputs, max_length=args.max_input_length, padding=\"max_length\", truncation=True)\n","\n","    # encode texts by prepending the task for input sequence and appending the test sequence\n","    # inputs = [args.prefix + text + \" \" + test for text, test in zip(texts, tests)]\n","    # model_inputs = tokenizer(inputs, max_length=args.max_input_length, padding=\"max_length\", truncation=True)\n","\n","    # encode texts by prepending the task for input sequence\n","    labels = tokenizer(codes, max_length=args.max_target_length, padding=\"max_length\", truncation=True).input_ids\n","\n","    # we need to replace the index of the padding tokens by -100\n","    # such that they are not taken into account by the CrossEntropyLoss\n","    labels_with_ignore_index = []\n","    for labels_example in labels:\n","        labels_example = [label if label != 0 else -100 for label in labels_example]\n","        labels_with_ignore_index.append(labels_example)\n","    model_inputs[\"labels\"] = labels_with_ignore_index\n","\n","    # return features\n","    return model_inputs\n","\n","\n","def get_train_tfdataset(train_dataset, num_train_examples, args):\n","    # select feature columns\n","    columns = ['input_ids', 'attention_mask', 'labels']\n","    # set to tensorflow format\n","    train_dataset.set_format(type='tensorflow', columns=columns)\n","\n","    # specify return types\n","    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, 'labels':tf.int32}\n","    # specify return shapes\n","    return_shapes = {'input_ids': tf.TensorShape([None]),'attention_mask': tf.TensorShape([None]), 'labels': tf.TensorShape([None])}\n","    # initialize dataset\n","    tf_dataset = tf.data.Dataset.from_generator(lambda : train_dataset, return_types, return_shapes)\n","\n","    # turn off auto-sharding\n","    options = tf.data.Options()\n","    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","    tf_dataset = tf_dataset.with_options(options)\n","\n","    # repeat, shuffle, batch, prefetch\n","    ds = (\n","        tf_dataset.repeat()\n","        .shuffle(num_train_examples, seed=args.seed)\n","        .batch(args.train_batch_size)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","\n","    # distribute dataset to devices\n","    return strategy.experimental_distribute_dataset(ds)\n","\n","def get_validation_tfdataset(eval_dataset, num_validation_examples, args):\n","    # select feature columns\n","    columns = ['input_ids', 'attention_mask', 'labels']\n","    # set to tensorflow format\n","    eval_dataset.set_format(type='tensorflow', columns=columns)\n","\n","    # specify return types\n","    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, 'labels':tf.int32}\n","    # specify return shapes\n","    return_shapes = {'input_ids': tf.TensorShape([None]),'attention_mask': tf.TensorShape([None]), 'labels': tf.TensorShape([None])}\n","    # initialize dataset\n","    tf_dataset = tf.data.Dataset.from_generator(lambda : eval_dataset, return_types, return_shapes)\n","\n","    # turn off auto-sharding\n","    options = tf.data.Options()\n","    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n","    tf_dataset = tf_dataset.with_options(options)\n","\n","    # repeat, batch, prefetch\n","    ds = (\n","        tf_dataset.repeat()\n","        .batch(args.validation_batch_size)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","\n","    # distribute dataset to devices\n","    return strategy.experimental_distribute_dataset(ds)"]},{"cell_type":"code","execution_count":null,"id":"d8e03f5d","metadata":{"execution":{"iopub.execute_input":"2022-04-21T14:41:34.415759Z","iopub.status.busy":"2022-04-21T14:41:34.414688Z","iopub.status.idle":"2022-04-21T14:41:34.416494Z","shell.execute_reply":"2022-04-21T14:41:34.416930Z","shell.execute_reply.started":"2022-04-21T12:13:24.876208Z"},"papermill":{"duration":0.039653,"end_time":"2022-04-21T14:41:34.417075","exception":false,"start_time":"2022-04-21T14:41:34.377422","status":"completed"},"tags":[],"id":"d8e03f5d","cellView":"form"},"outputs":[],"source":["# @title\n","def fix_all_seeds(seed):\n","    # set random seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","def init_logger(log_file=None, log_file_level=logging.NOTSET):\n","    # initialize logger for tracking events and save in file\n","    if isinstance(log_file, Path):\n","        log_file = str(log_file)\n","    log_format = logging.Formatter(\n","        fmt='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","        datefmt='%m/%d/%Y %H:%M:%S'\n","    )\n","    logger = logging.getLogger()\n","    logger.setLevel(logging.INFO)\n","    console_handler = logging.StreamHandler()\n","    console_handler.setFormatter(log_format)\n","    logger.handlers = [console_handler]\n","    if log_file and log_file != '':\n","        file_handler = logging.FileHandler(log_file)\n","        file_handler.setLevel(log_file_level)\n","        # file_handler.setFormatter(log_format)\n","        logger.addHandler(file_handler)\n","    return logger\n","\n","class ProgressBar(object):\n","    # custom progress bar\n","    def __init__(self, n_total,width=30,desc = 'Training'):\n","        self.width = width\n","        self.n_total = n_total\n","        self.start_time = time.time()\n","        self.desc = desc\n","\n","    def __call__(self, step, info={}):\n","        now = time.time()\n","        current = step + 1\n","        recv_per = current / self.n_total\n","        bar = f'[{self.desc}] {current}/{self.n_total} ['\n","        if recv_per >= 1:\n","            recv_per = 1\n","        prog_width = int(self.width * recv_per)\n","        if prog_width > 0:\n","            bar += '=' * (prog_width - 1)\n","            if current< self.n_total:\n","                bar += \">\"\n","            else:\n","                bar += '='\n","        bar += '.' * (self.width - prog_width)\n","        bar += ']'\n","        show_bar = f\"\\r{bar}\"\n","        time_per_unit = (now - self.start_time) / current\n","        if current < self.n_total:\n","            eta = time_per_unit * (self.n_total - current)\n","            if eta > 3600:\n","                eta_format = ('%d:%02d:%02d' %\n","                              (eta // 3600, (eta % 3600) // 60, eta % 60))\n","            elif eta > 60:\n","                eta_format = '%d:%02d' % (eta // 60, eta % 60)\n","            else:\n","                eta_format = '%ds' % eta\n","            time_info = f' - ETA: {eta_format}'\n","        else:\n","            if time_per_unit >= 1:\n","                time_info = f' {time_per_unit:.1f}s/step'\n","            elif time_per_unit >= 1e-3:\n","                time_info = f' {time_per_unit * 1e3:.1f}ms/step'\n","            else:\n","                time_info = f' {time_per_unit * 1e6:.1f}us/step'\n","\n","        show_bar += time_info\n","        if len(info) != 0:\n","            show_info = f'{show_bar} ' + \\\n","                        \"-\".join([f' {key}: {value:.4f} ' if key != \"learning_rate\" else f' {key}: {value:.8f} ' for key, value in info.items()])\n","            print(show_info, end='')\n","        else:\n","            print(show_bar, end='')"]},{"cell_type":"code","execution_count":null,"id":"cff649b4","metadata":{"execution":{"iopub.execute_input":"2022-04-21T14:41:34.528720Z","iopub.status.busy":"2022-04-21T14:41:34.526882Z","iopub.status.idle":"2022-04-21T14:41:34.529394Z","shell.execute_reply":"2022-04-21T14:41:34.529860Z","shell.execute_reply.started":"2022-04-21T12:13:24.895982Z"},"papermill":{"duration":0.054201,"end_time":"2022-04-21T14:41:34.530014","exception":false,"start_time":"2022-04-21T14:41:34.475813","status":"completed"},"tags":[],"id":"cff649b4"},"outputs":[],"source":["class Trainer:\n","    def __init__(\n","        self, model, args, train_dataset, validation_dataset,\n","        num_train_examples, num_validation_examples\n","    ):\n","        self.model = model\n","        self.args = args\n","\n","        self.train_dataset = train_dataset\n","        self.num_train_examples = num_train_examples\n","\n","        self.validation_dataset = validation_dataset\n","        self.num_validation_examples = num_validation_examples\n","\n","        self.global_step = 0\n","        self.eval_loss = tf.keras.metrics.Sum()\n","\n","    def create_optimizer_and_scheduler(self, num_training_steps):\n","        # creates an optimizer with a learning rate schedule using a warmup phase followed by a linear decay.\n","        num_warmup_steps = math.ceil(num_training_steps * self.args.warmup_ratio)\n","        self.optimizer, self.lr_scheduler = create_optimizer(\n","            init_lr=self.args.learning_rate,\n","            num_train_steps=num_training_steps,\n","            num_warmup_steps=num_warmup_steps,\n","            weight_decay_rate=self.args.weight_decay,\n","            adam_epsilon=self.args.adam_epsilon\n","        )\n","\n","    def evaluation_step(self, features, labels, nb_instances_in_global_batch):\n","        # forward pass\n","        outputs = self.model(input_ids=features['input_ids'], attention_mask=features['attention_mask'], labels=labels, training=False)[:2]\n","        loss, logits = outputs[:2]\n","        # loss scaling\n","        scaled_loss = loss / tf.cast(nb_instances_in_global_batch, dtype=loss.dtype)\n","        # add current batch loss\n","        self.eval_loss.update_state(scaled_loss)\n","\n","    @tf.function\n","    def distributed_evaluation_steps(self, batch):\n","        features = {k: v for k, v in batch.items() if 'labels' not in k}\n","        labels = batch['labels']\n","        nb_instances = tf.reduce_sum(tf.cast(labels != -100, dtype=tf.int32))\n","        # strategy.run() expects args to be a list or tuple\n","        inputs = (features, labels, nb_instances)\n","        # `run` replicates the provided computation and runs with the distributed input\n","        strategy.run(self.evaluation_step, inputs)\n","\n","    def evaluate(self):\n","        # calculate total validation steps\n","        steps = math.ceil(self.num_validation_examples / self.args.validation_batch_size)\n","        # reset eval loss after every epoch\n","        self.eval_loss.reset_states()\n","        logs = {}\n","        pbar = ProgressBar(n_total=steps, desc='Evaluating')\n","        # iterate over validation dataset\n","        for step, batch in enumerate(self.validation_dataset):\n","            # distributed evaluation step\n","            self.distributed_evaluation_steps(batch)\n","            logs[\"eval_loss\"] = self.eval_loss.result() / (step + 1)\n","            pbar(step=step, info=logs)\n","            if step == steps - 1:\n","                break\n","        print(\"\\n------------- validation result -----------------\")\n","\n","    def apply_gradients(self, features, labels, nb_instances_in_global_batch):\n","        # forward pass\n","        outputs = self.model(input_ids=features['input_ids'], attention_mask=features['attention_mask'], labels=labels, training=True)[:2]\n","        loss, logits = outputs[:2]\n","        # loss scaling\n","        scaled_loss = loss / tf.cast(nb_instances_in_global_batch, dtype=loss.dtype)\n","        # calculate gradients\n","        gradients = tf.gradients(scaled_loss, self.model.trainable_variables)\n","        # convert gradients with nan value\n","        gradients = [g if g is not None else tf.zeros_like(v) for g, v in zip(gradients, self.model.trainable_variables)]\n","        # optimize the model\n","        self.optimizer.apply_gradients(list(zip(gradients, self.model.trainable_variables)))\n","        # add current batch loss\n","        self.train_loss.update_state(scaled_loss)\n","\n","    @tf.function\n","    def distributed_training_steps(self, batch):\n","        with strategy.scope():\n","            features = {k: v for k, v in batch.items() if 'labels' not in k}\n","            labels = batch['labels']\n","            nb_instances = tf.reduce_sum(tf.cast(labels != -100, dtype=tf.int32))\n","            # strategy.run() expects args to be a list or tuple\n","            inputs = (features, labels, nb_instances)\n","            # `run` replicates the provided computation and runs with the distributed input.\n","            strategy.run(self.apply_gradients, inputs)\n","\n","    def train(self):\n","        # calculate total training steps\n","        num_updates_per_epoch = self.num_train_examples // args.train_batch_size\n","        self.steps_per_epoch = num_updates_per_epoch\n","        t_total = self.steps_per_epoch * self.args.epochs\n","\n","        with strategy.scope():\n","            # optimizer, and checkpoint must be created under `strategy.scope`\n","            # create optimizer and scheduler\n","            self.create_optimizer_and_scheduler(num_training_steps=t_total)\n","\n","            # create checkpoint manager\n","            folder = os.path.join(self.args.output_dir, self.args.checkpoint_dir)\n","            ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n","            self.model.ckpt_manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n","            iterations = self.optimizer.iterations\n","\n","            logger.info(\"***** Running training *****\")\n","            logger.info(f\"  Num examples = {self.num_train_examples}\")\n","            logger.info(f\"  Num Epochs = {self.args.epochs}\")\n","            logger.info(f\"  Total train batch size (w. parallel & distributed) = {self.args.train_batch_size * n_replicas(strategy)}\")\n","            logger.info(f\"  Steps per epoch = {self.steps_per_epoch}\")\n","            logger.info(f\"  Total optimization steps = {t_total}\")\n","\n","            self.train_loss = tf.keras.metrics.Sum(name=\"training_loss\")\n","            start_time = datetime.datetime.now()\n","            for epoch_iter in range(self.args.epochs):\n","                # training loop\n","                logger.info(f\"Epoch {epoch_iter + 1}/{self.args.epochs}\")\n","\n","                pbar = ProgressBar(n_total=self.steps_per_epoch, desc='Training')\n","                # iterate over training dataset\n","                for step, batch in enumerate(self.train_dataset):\n","                    # distributed training step\n","                    self.distributed_training_steps(batch)\n","\n","                    self.global_step = iterations.numpy()\n","                    training_loss = self.train_loss.result() / (step + 1)\n","\n","                    logs = {}\n","                    logs[\"training_loss\"] = training_loss.numpy()\n","                    logs[\"learning_rate\"] = self.lr_scheduler(self.global_step).numpy()\n","                    pbar(step=step, info=logs)\n","\n","                    if self.global_step % self.steps_per_epoch == 0:\n","                        print(\"\\n------------- train result -----------------\")\n","                        # call to evaluation loop\n","                        self.evaluate()\n","                        # save checkpoint\n","                        ckpt_save_path = self.model.ckpt_manager.save()\n","                        logger.info(f\"Saving checkpoint at {ckpt_save_path}\")\n","                        break\n","\n","                # reset train loss after every epoch\n","                self.train_loss.reset_states()\n","            end_time = datetime.datetime.now()\n","            logger.info(f\"Training took: {str(end_time - start_time)}\")"]},{"cell_type":"code","execution_count":null,"id":"5cbb3267","metadata":{"execution":{"iopub.execute_input":"2022-04-21T14:41:34.620423Z","iopub.status.busy":"2022-04-21T14:41:34.619584Z","iopub.status.idle":"2022-04-21T14:41:34.621558Z","shell.execute_reply":"2022-04-21T14:41:34.621967Z","shell.execute_reply.started":"2022-04-21T12:13:24.929780Z"},"papermill":{"duration":0.031726,"end_time":"2022-04-21T14:41:34.622121","exception":false,"start_time":"2022-04-21T14:41:34.590395","status":"completed"},"tags":[],"id":"5cbb3267"},"outputs":[],"source":["def run(args):\n","    logger.info(\" Starting training / evaluation\")\n","\n","    logger.info(\" Downloading Data Files\")\n","    dataset_path = download_dataset(args.cache_dir)\n","\n","    logger.info(\" Loading Data Files\")\n","    dataset = load_dataset('json', data_files=dataset_path)\n","    # train test split\n","    dataset = dataset['train'].train_test_split(0.1, shuffle=False)\n","\n","    logger.info(\" Initializing Tokenizer\")\n","    tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name)\n","\n","    logger.info(\" Preparing Features\")\n","    dataset = dataset.map(convert_examples_to_features, batched=True, fn_kwargs={\"tokenizer\":tokenizer, \"args\":args})\n","\n","    logger.info(\" Intializing training and validation dataset \")\n","    train_dataset = dataset['train']\n","    num_train_examples = len(dataset['train'])\n","    # create tf train dataset\n","    tf_train_dataset = get_train_tfdataset(train_dataset, num_train_examples, args)\n","\n","    validation_dataset = dataset['test']\n","    num_validation_examples = len(dataset['test'])\n","    # create tf validation dataset\n","    tf_validation_dataset = get_validation_tfdataset(train_dataset, num_validation_examples, args)\n","\n","    logger.info(f' Intializing model | {args.model_type.upper()} ')\n","    with strategy.scope():\n","        # model must be created under `strategy.scope`\n","        model = TFT5ForConditionalGeneration.from_pretrained(args.model_name_or_path, from_pt=True)\n","\n","    # custom training loop\n","    trainer = Trainer(model, args, tf_train_dataset, tf_validation_dataset, num_train_examples, num_validation_examples)\n","    trainer.train()\n","\n","    # save pretrained model and tokenizer\n","    logger.info(f\" Saving model in {args.save_dir}\")\n","    trainer.model.save_pretrained(args.save_dir)\n","    tokenizer.save_pretrained(args.save_dir)"]},{"cell_type":"code","execution_count":null,"id":"782e54c3","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-04-21T14:41:34.708529Z","iopub.status.busy":"2022-04-21T14:41:34.707631Z","iopub.status.idle":"2022-04-21T15:02:12.980082Z","shell.execute_reply":"2022-04-21T15:02:12.979615Z","shell.execute_reply.started":"2022-04-21T12:13:24.941619Z"},"papermill":{"duration":1238.300043,"end_time":"2022-04-21T15:02:12.980351","exception":false,"start_time":"2022-04-21T14:41:34.680308","status":"completed"},"tags":[],"colab":{"referenced_widgets":["10316615b6b6481a9aaf0783ebc9b627","cabd000858534783a4a66bd09cb7f5c4","bcb0ecd80c4845be8ba20ee56794a736","d395fe0992c543219f4713e95f9c810a","39012f3d58784b3282a1804e54535b4e","3441d035fddd43a6af03e3d7633a12f1","e8d3d7abc081477d9f3c81f2ee7cf703","95d6033643fb4be8a568763ec3d74df8","405e31075169426f8e9eb443f0ad96bb","706920a67bfc45f7b16e579ed858a37e","3ab3a699fc804ac3a6c261d4cfe3202d","b104159764dd4280b048052dfc01ffd2"]},"id":"782e54c3","outputId":"f7109f44-5630-41d7-9ce6-45ee29aa067b"},"outputs":[{"name":"stderr","output_type":"stream","text":["04/21/2022 14:41:34 - INFO - root -    Starting training / evaluation\n","04/21/2022 14:41:34 - INFO - root -    Downloading Data Files\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://raw.githubusercontent.com/google-research/google-research/master/mbpp/mbpp.jsonl\n","565248/563743 [==============================] - 0s 0us/step\n","573440/563743 [==============================] - 0s 0us/step\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:41:35 - INFO - root -    Loading Data Files\n","04/21/2022 14:41:35 - WARNING - datasets.builder -   Using custom data configuration default-82fe3e58ac1966f8\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10316615b6b6481a9aaf0783ebc9b627","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cabd000858534783a4a66bd09cb7f5c4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcb0ecd80c4845be8ba20ee56794a736","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:41:35 - INFO - root -    Initializing Tokenizer\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d395fe0992c543219f4713e95f9c810a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39012f3d58784b3282a1804e54535b4e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/687k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3441d035fddd43a6af03e3d7633a12f1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/287k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8d3d7abc081477d9f3c81f2ee7cf703","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95d6033643fb4be8a568763ec3d74df8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:41:42 - INFO - root -    Preparing Features\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"405e31075169426f8e9eb443f0ad96bb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"706920a67bfc45f7b16e579ed858a37e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:41:45 - INFO - root -    Intializing training and validation dataset \n","04/21/2022 14:41:45 - INFO - root -    Intializing model | T5 \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ab3a699fc804ac3a6c261d4cfe3202d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b104159764dd4280b048052dfc01ffd2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-04-21 14:42:17.180076: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","04/21/2022 14:42:21 - INFO - root -   ***** Running training *****\n","04/21/2022 14:42:21 - INFO - root -     Num examples = 876\n","04/21/2022 14:42:21 - INFO - root -     Num Epochs = 20\n","04/21/2022 14:42:21 - INFO - root -     Total train batch size (w. parallel & distributed) = 8\n","04/21/2022 14:42:21 - INFO - root -     Steps per epoch = 109\n","04/21/2022 14:42:21 - INFO - root -     Total optimization steps = 2180\n","04/21/2022 14:42:21 - INFO - root -   Epoch 1/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 3.1s/step  training_loss: 3.6843 - learning_rate: 0.00007500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 914.7ms/step  eval_loss: 1.5429 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:48:27 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-1\n","04/21/2022 14:48:27 - INFO - root -   Epoch 2/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 255.7ms/step  training_loss: 1.5106 - learning_rate: 0.00015000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 5.0s/step  eval_loss: 1.0644 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:50:10 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-2\n","04/21/2022 14:50:11 - INFO - root -   Epoch 3/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 258.0ms/step  training_loss: 1.2020 - learning_rate: 0.00022500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.3ms/step  eval_loss: 0.8043 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:50:49 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-3\n","04/21/2022 14:50:50 - INFO - root -   Epoch 4/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 259.2ms/step  training_loss: 0.9767 - learning_rate: 0.00030000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 76.2ms/step  eval_loss: 0.6287 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:51:28 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-4\n","04/21/2022 14:51:28 - INFO - root -   Epoch 5/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 258.6ms/step  training_loss: 0.8047 - learning_rate: 0.00028125 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.7ms/step  eval_loss: 0.4416 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:52:07 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-5\n","04/21/2022 14:52:08 - INFO - root -   Epoch 6/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 259.7ms/step  training_loss: 0.6212 - learning_rate: 0.00026250 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 79.4ms/step  eval_loss: 0.3410 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:52:47 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-6\n","04/21/2022 14:52:47 - INFO - root -   Epoch 7/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 258.2ms/step  training_loss: 0.4821 - learning_rate: 0.00024375 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.2ms/step  eval_loss: 0.2421 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:53:26 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-7\n","04/21/2022 14:53:28 - INFO - root -   Epoch 8/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 259.3ms/step  training_loss: 0.3874 - learning_rate: 0.00022500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.4ms/step  eval_loss: 0.1564 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:54:07 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-8\n","04/21/2022 14:54:07 - INFO - root -   Epoch 9/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 258.8ms/step  training_loss: 0.2998 - learning_rate: 0.00020625 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 75.2ms/step  eval_loss: 0.1062 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:54:46 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-9\n","04/21/2022 14:54:46 - INFO - root -   Epoch 10/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 259.1ms/step  training_loss: 0.2476 - learning_rate: 0.00018750 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.3ms/step  eval_loss: 0.0675 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:55:25 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-10\n","04/21/2022 14:55:25 - INFO - root -   Epoch 11/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 258.3ms/step  training_loss: 0.1836 - learning_rate: 0.00016875 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.3ms/step  eval_loss: 0.0429 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:56:04 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-11\n","04/21/2022 14:56:06 - INFO - root -   Epoch 12/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 257.0ms/step  training_loss: 0.1393 - learning_rate: 0.00015000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 83.5ms/step  eval_loss: 0.0317 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:56:45 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-12\n","04/21/2022 14:56:47 - INFO - root -   Epoch 13/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 257.0ms/step  training_loss: 0.1142 - learning_rate: 0.00013125 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 74.1ms/step  eval_loss: 0.0257 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:57:26 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-13\n","04/21/2022 14:57:28 - INFO - root -   Epoch 14/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 258.0ms/step  training_loss: 0.0865 - learning_rate: 0.00011250 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.4ms/step  eval_loss: 0.0139 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:58:07 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-14\n","04/21/2022 14:58:07 - INFO - root -   Epoch 15/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 257.8ms/step  training_loss: 0.0706 - learning_rate: 0.00009375 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 90.5ms/step  eval_loss: 0.0101 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:58:47 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-15\n","04/21/2022 14:58:48 - INFO - root -   Epoch 16/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 257.0ms/step  training_loss: 0.0522 - learning_rate: 0.00007500 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.6ms/step  eval_loss: 0.0078 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 14:59:28 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-16\n","04/21/2022 14:59:29 - INFO - root -   Epoch 17/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 259.8ms/step  training_loss: 0.0445 - learning_rate: 0.00005625 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 79.1ms/step  eval_loss: 0.0041 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:00:08 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-17\n","04/21/2022 15:00:08 - INFO - root -   Epoch 18/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 257.2ms/step  training_loss: 0.0367 - learning_rate: 0.00003750 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 79.2ms/step  eval_loss: 0.0029 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:00:47 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-18\n","04/21/2022 15:00:47 - INFO - root -   Epoch 19/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 260.0ms/step  training_loss: 0.0313 - learning_rate: 0.00001875 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 77.7ms/step  eval_loss: 0.0024 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:01:26 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-19\n","04/21/2022 15:01:28 - INFO - root -   Epoch 20/20\n"]},{"name":"stdout","output_type":"stream","text":["[Training] 109/109 [==============================] 256.8ms/step  training_loss: 0.0290 - learning_rate: 0.00000000 \n","------------- train result -----------------\n","[Evaluating] 13/13 [==============================] 78.2ms/step  eval_loss: 0.0024 \n","------------- validation result -----------------\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:07 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-20\n","04/21/2022 15:02:07 - INFO - root -   Training took: 0:19:46.308197\n","04/21/2022 15:02:07 - INFO - root -    Saving model in runs//saved_model/\n"]}],"source":["class Args:\n","    # define training arguments\n","\n","    # MODEL\n","    model_type = 't5'\n","    tokenizer_name = 'Salesforce/codet5-base'\n","    model_name_or_path = 'Salesforce/codet5-base'\n","\n","    # DATA\n","    train_batch_size = 8\n","    validation_batch_size = 8\n","    max_input_length = 48\n","    max_target_length = 128\n","    prefix = \"Generate Python: \"\n","\n","    # OPTIMIZER\n","    learning_rate = 3e-4\n","    weight_decay = 1e-4\n","    warmup_ratio = 0.2\n","    adam_epsilon = 1e-8\n","\n","    # TRAINING\n","    seed = 2022\n","    epochs = 20\n","\n","    # DIRECTORIES\n","    output_dir = \"runs/\"\n","    logging_dir = f\"{output_dir}/logs/\"\n","    checkpoint_dir = f\"checkpoint\"\n","    save_dir = f\"{output_dir}/saved_model/\"\n","    cache_dir = '../working/'\n","    Path(output_dir).mkdir(parents=True, exist_ok=True)\n","    Path(logging_dir).mkdir(parents=True, exist_ok=True)\n","    Path(save_dir).mkdir(parents=True, exist_ok=True)\n","\n","\n","# initialize training arguments\n","args = Args()\n","# initialize logger\n","logger = init_logger(log_file=os.path.join(args.logging_dir, f\"{args.model_type}-{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}.log\"))\n","# fix all seeds\n","fix_all_seeds(args.seed)\n","\n","if __name__ == \"__main__\":\n","    # run training and evaluation\n","    dataset = run(args)"]},{"cell_type":"code","execution_count":null,"id":"7b198e92","metadata":{"execution":{"iopub.execute_input":"2022-04-21T15:02:16.317528Z","iopub.status.busy":"2022-04-21T15:02:16.315854Z","iopub.status.idle":"2022-04-21T15:02:16.318135Z","shell.execute_reply":"2022-04-21T15:02:16.318553Z","shell.execute_reply.started":"2022-04-21T12:34:12.767944Z"},"papermill":{"duration":1.039229,"end_time":"2022-04-21T15:02:16.318697","exception":false,"start_time":"2022-04-21T15:02:15.279468","status":"completed"},"tags":[],"id":"7b198e92"},"outputs":[],"source":["def run_predict(args, text):\n","    # load saved finetuned model\n","    model = TFT5ForConditionalGeneration.from_pretrained(args.save_dir)\n","    # load saved tokenizer\n","    tokenizer = RobertaTokenizer.from_pretrained(args.save_dir)\n","\n","     # encode texts by prepending the task for input sequence and appending the test sequence\n","    query = args.prefix + text\n","    encoded_text = tokenizer(query, return_tensors='tf', padding='max_length', truncation=True, max_length=args.max_input_length)\n","\n","    # inference\n","    generated_code = model.generate(\n","        encoded_text[\"input_ids\"], attention_mask=encoded_text[\"attention_mask\"],\n","        max_length=args.max_target_length, top_p=0.95, top_k=50, repetition_penalty=2, num_return_sequences=1\n","    )\n","\n","    # decode generated tokens\n","    decoded_code = tokenizer.decode(generated_code.numpy()[0], skip_special_tokens=True)\n","    return decoded_code\n","\n","def predict_from_dataset(args):\n","    # load using hf datasets\n","    dataset = load_dataset('json', data_files='../working/mbpp.jsonl')\n","    # train test split\n","    dataset = dataset['train'].train_test_split(0.1, shuffle=False)\n","    test_dataset = dataset['test']\n","\n","    # randomly select an index from the validation dataset\n","    index = random.randint(0, len(test_dataset))\n","    text = test_dataset[index]['text']\n","    code = test_dataset[index]['code']\n","\n","    # run-predict on text\n","    decoded_code = run_predict(args, text)\n","\n","    print(\"#\" * 25); print(\"QUERY: \", text);\n","    print()\n","    print('#' * 25); print(\"ORIGINAL: \"); print(\"\\n\", code);\n","    print()\n","    print('#' * 25); print(\"GENERATED: \"); print(\"\\n\", decoded_code);\n","\n","def predict_from_text(args, text):\n","    # run-predict on text\n","    decoded_code = run_predict(args, text)\n","    print(\"#\" * 25); print(\"QUERY: \", text);\n","    print()\n","    print('#' * 25); print(\"GENERATED: \"); print(\"\\n\", decoded_code);"]},{"cell_type":"markdown","id":"c03869c0","metadata":{"papermill":{"duration":0.80672,"end_time":"2022-04-21T15:02:17.898195","exception":false,"start_time":"2022-04-21T15:02:17.091475","status":"completed"},"tags":[],"id":"c03869c0"},"source":["<a id=\"section12a\"><font color='#425066'><h3>Predict from Dataset</h3></font></a>"]},{"cell_type":"code","execution_count":null,"id":"73a18614","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-04-21T15:02:19.463457Z","iopub.status.busy":"2022-04-21T15:02:19.462816Z","iopub.status.idle":"2022-04-21T15:02:41.941221Z","shell.execute_reply":"2022-04-21T15:02:41.940701Z","shell.execute_reply.started":"2022-04-21T12:34:12.795910Z"},"papermill":{"duration":23.235842,"end_time":"2022-04-21T15:02:41.941361","exception":false,"start_time":"2022-04-21T15:02:18.705519","status":"completed"},"tags":[],"colab":{"referenced_widgets":["745b026719d248009282110cae1af4f6","a11f9c0023fe44e78c8a340a0dcd0e1c","7283e221f5564b7681226532da00e280"]},"id":"73a18614","outputId":"1bafffcb-eb23-45f3-c33d-c51e8aaddad7"},"outputs":[{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:20 - WARNING - datasets.builder -   Using custom data configuration default-82fe3e58ac1966f8\n","04/21/2022 15:02:20 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"745b026719d248009282110cae1af4f6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:20 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-64c56dfca2d42905.arrow and /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-84194af6b1765ad6.arrow\n"]},{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to convert the given tuples into set.\n","\n","#########################\n","ORIGINAL: \n","\n"," def tuple_to_set(t):\r\n","  s = set(t)\r\n","  return (s) \n","\n","#########################\n","GENERATED: \n","\n"," def tuple_set(test_tup):\r\n","  res = set([tuple() for ele in test_ t up]) \r\n","  return (res)\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:26 - WARNING - datasets.builder -   Using custom data configuration default-82fe3e58ac1966f8\n","04/21/2022 15:02:26 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a11f9c0023fe44e78c8a340a0dcd0e1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:26 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-64c56dfca2d42905.arrow and /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-84194af6b1765ad6.arrow\n"]},{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to check for a number at the end of a string.\n","\n","#########################\n","ORIGINAL: \n","\n"," import re\r\n","def end_num(string):\r\n","    text = re.compile(r\".*[0-9]$\")\r\n","    if text.match(string):\r\n","        return True\r\n","    else:\r\n","        return False\n","\n","#########################\n","GENERATED: \n","\n"," def check_number(text):\r\n","  if re.search(\"[0-9]\", text) : \r\n","    return (\"Valid\")   else:    \r\n","      return \"Invalid\"\n"]},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:35 - WARNING - datasets.builder -   Using custom data configuration default-82fe3e58ac1966f8\n","04/21/2022 15:02:35 - WARNING - datasets.builder -   Reusing dataset json (/root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7283e221f5564b7681226532da00e280","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["04/21/2022 15:02:35 - WARNING - datasets.arrow_dataset -   Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-64c56dfca2d42905.arrow and /root/.cache/huggingface/datasets/json/default-82fe3e58ac1966f8/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-84194af6b1765ad6.arrow\n"]},{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to convert camel case string to snake case string by using regex.\n","\n","#########################\n","ORIGINAL: \n","\n"," import re\r\n","def camel_to_snake(text):\r\n","  str1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', text)\r\n","  return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', str1).lower()\n","\n","#########################\n","GENERATED: \n","\n"," import re\r\n","def snake_to_camel(word):\r\n","  return ''.join([x for x in word if len('_') == 1])\n"]}],"source":["# example 1\n","predict_from_dataset(args)\n","# example 2\n","predict_from_dataset(args)\n","# example 3\n","predict_from_dataset(args)"]},{"cell_type":"markdown","id":"6f94c82b","metadata":{"papermill":{"duration":0.750688,"end_time":"2022-04-21T15:02:43.468794","exception":false,"start_time":"2022-04-21T15:02:42.718106","status":"completed"},"tags":[],"id":"6f94c82b"},"source":["<a id=\"section12b\"><font color='#425066'><h3>Predict from Text</h3></font></a>"]},{"cell_type":"code","execution_count":null,"id":"d94370e4","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-04-21T15:02:44.981575Z","iopub.status.busy":"2022-04-21T15:02:44.980741Z","iopub.status.idle":"2022-04-21T15:03:23.498240Z","shell.execute_reply":"2022-04-21T15:03:23.498842Z","shell.execute_reply.started":"2022-04-21T12:34:43.909881Z"},"papermill":{"duration":39.27622,"end_time":"2022-04-21T15:03:23.499021","exception":false,"start_time":"2022-04-21T15:02:44.222801","status":"completed"},"tags":[],"id":"d94370e4","outputId":"1d829660-b192-485d-a7d7-951a3796bebf"},"outputs":[{"name":"stdout","output_type":"stream","text":["#########################\n","QUERY:  Write a function to add two random numbers\n","\n","#########################\n","GENERATED: \n","\n"," def add_random(a,b):\r\n","    if a + b > c:\r\n","        return None\r\n","     else::\r\n","         random = [0 for i in range (min()], max((gcd(), num)) % d])] \r\n","      result1=add(_[i]|\"\")\r\n","  while len($result2), 1 >=len('x') and count < 2]:\r\n","   temp.append([j]))\r\n","                sums += yield from hash sdict\n","\n","#########################\n","QUERY:  Write a function to find the frequency of items in a list\n","\n","#########################\n","GENERATED: \n","\n"," import collections\r\n","def freq_count(list1): \r\n","    dict = defaultdict()   for i in list 1: \r\n","        keys=dict.keys():    \r\n","            value[i] += one\r\n","    dic_data = {}\r\n","    if key notin dictionary._values]:      return {key :value}\r\n","         else::################################        , values=[dictionary[:-one]]]) \n","\n","#########################\n","QUERY:  Write a function to concatenate two dictionary\n","\n","#########################\n","GENERATED: \n","\n"," def concatenate_dict(d1, d2):\r\n","    result = {k: v for k, val in dict.items() if not n % len([key] + value) == 0])} \r\n","    return list (result).values())\n","\n"]}],"source":["# example 1\n","predict_from_text(args, \"Write a function to add two random numbers\"); print()\n","# example 2\n","predict_from_text(args, \"Write a function to find the frequency of items in a list\"); print()\n","# example 3\n","predict_from_text(args, \"Write a function to concatenate two dictionary\"); print()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":1349.363152,"end_time":"2022-04-21T15:03:29.260899","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-04-21T14:40:59.897747","version":"2.3.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}